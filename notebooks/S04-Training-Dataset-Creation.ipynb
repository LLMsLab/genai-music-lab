{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the Training Dataset\n",
    "\n",
    "The success of fine-tuning a large language model, especially for a\n",
    "specialized task such as generating music inspired by Beethoven's\n",
    "sonatas, heavily relies on the quality and structure of the training\n",
    "dataset. The dataset should be both representative of the desired output\n",
    "and diverse enough to capture the nuances of the musical style.\n",
    "\n",
    "### Dataset Structure\n",
    "\n",
    "The dataset is structured as a series of conversations, mimicking the\n",
    "format of the Chat completions API. Each conversation consists of a list\n",
    "of messages, where each message has a role (`system`, `user`, or\n",
    "`assistant`), content (the actual text of the message), and an optional\n",
    "name.\n",
    "\n",
    "The `system` message sets the context for the conversation, the `user`\n",
    "message provides a prompt or instruction, and the `assistant` message\n",
    "offers the ideal response we want the model to generate.\n",
    "\n",
    "### Illustrative Example\n",
    "\n",
    "Consider the task of generating a melody inspired by Beethoven's\n",
    "sonatas. The training dataset might look something like this:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a music generator inspired by Beethoven's sonatas.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Generate a melody in C major.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"melody_pitch_duration_data: [[60, 0.5], [62, 0.25], [64, 0.25], [65, 0.5], [67, 0.5], [69, 0.25], [71, 0.25], [72, 1.0]]\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a music generator inspired by Beethoven's sonatas.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Compose a short piece in A minor.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"melody_pitch_duration_data: [[57, 0.5], [59, 0.25], [60, 0.25], [62, 0.5], [64, 0.5], [65, 0.25], [67, 0.25], [69, 1.0]]\"}\n",
    "        ]\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "In the above example, the `system` message sets the context, indicating\n",
    "that the model should generate music inspired by Beethoven's sonatas.\n",
    "The `user` message provides a specific instruction, such as the key in\n",
    "which the melody should be composed. The `assistant` message then\n",
    "provides the ideal response in the form of a pitch-duration\n",
    "representation of the melody.\n",
    "\n",
    "### Considerations\n",
    "\n",
    "1. **Diversity**: It's crucial to ensure that the training dataset\n",
    "   encompasses a wide range of musical styles, keys, and structures\n",
    "   found in Beethoven's sonatas. This will enable the model to\n",
    "   generalize better and produce varied outputs.\n",
    "\n",
    "2. **Quality**: The ideal responses in the dataset should be of high\n",
    "   musical quality. They should adhere to the principles of music theory\n",
    "   and capture the essence of Beethoven's style.\n",
    "\n",
    "3. **Size**: While the exact number of examples required can vary,\n",
    "   starting with a set of 50 to 100 well-crafted demonstrations is\n",
    "   recommended. This provides a solid foundation, and the dataset can be\n",
    "   expanded based on initial results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My idea is to use the long prompt above to help generate text representation of music as pith-duration pairs once the model is fine-tuned. But now I am wondering if I do not provide the prompt during the fine-tuning process because I provide the content of the illustrative training dataset how the large language model can really learn this kind of input:\n",
    "\n",
    "\"melody_pitch_duration_data: [[60, 0.5], [62, 0.25], [64, 0.25], [65, 0.5], [67, 0.5], [69, 0.25], [71, 0.25], [72, 1.0]]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your concern is valid. The fine-tuning process is about teaching the\n",
    "model a specific behavior or knowledge based on the provided dataset. If\n",
    "the dataset doesn't contain examples that align with the desired output\n",
    "format, the model might not generate outputs in that format even if you\n",
    "use a detailed prompt later on.\n",
    "\n",
    "To ensure that the model understands and can generate the desired\n",
    "\"melody_pitch_duration_data\" format, you should include it in your\n",
    "fine-tuning dataset. Here's how you can approach this:\n",
    "\n",
    "1. **Dataset Structure**: Your training dataset should be structured in\n",
    "   a way that it mimics the desired interaction with the model. If you\n",
    "   want the model to produce outputs in the \"melody_pitch_duration_data\"\n",
    "   format, then your training examples should contain conversations\n",
    "   where this format is used.\n",
    "\n",
    "2. **Explicit Instructions**: In your training dataset, include explicit\n",
    "   system instructions or user prompts that ask for music in the\n",
    "   \"melody_pitch_duration_data\" format. This will teach the model the\n",
    "   kind of responses you expect.\n",
    "\n",
    "3. **Variability**: Ensure that your training dataset contains a variety\n",
    "   of musical examples in the desired format. This will help the model\n",
    "   generalize better and produce diverse musical outputs.\n",
    "\n",
    "4. **Prompt Engineering**: Once the model is fine-tuned, you can still\n",
    "   use your long prompt to guide the model. However, since the model has\n",
    "   seen examples of the desired format during fine-tuning, it will be\n",
    "   more likely to produce outputs in that format.\n",
    "\n",
    "For example, a few training conversations might look like:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are a music AI that generates melodies in the melody_pitch_duration_data format.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Generate a short melody for me.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"melody_pitch_duration_data: [[60, 0.5], [62, 0.25], [64, 0.25], [65, 0.5]]\"}\n",
    "  ]\n",
    "},\n",
    "{\n",
    "  \"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are a music AI that generates melodies in the melody_pitch_duration_data format.\"},\n",
    "    {\"role\": \"user\", \"content\": \"I need a melody inspired by a sunrise.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"melody_pitch_duration_data: [[64, 0.5], [66, 0.25], [68, 0.25], [69, 0.5], [71, 0.5]]\"}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "By including such examples in your training dataset, you're explicitly\n",
    "teaching the model the kind of interaction and output format you desire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
