{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationStringBufferMemory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "from midiutil import MIDIFile\n",
    "import mido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "\n",
    "# Load the config file\n",
    "config = omegaconf.OmegaConf.load(\"../config/main.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = config['prompt_text_to_melody']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I need assistance in producing AI-generated text that I convert to music using MIDI files. Initially'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature=0.9\n",
    "llm_model = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=temperature, model=llm_model)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YES'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Certainly, I can generate a longer \"sad\" and \"dramatic\" melody for you. Sad and dramatic melodies often involve minor keys, slower rhythms, larger leaps in intervals, and varied dynamics. Here is a more extended melody with these qualities:\\n\\n```python\\nmelody_pitch_duration_data = [\\n  (57, 0.5),   # A3 half note\\n  (0, 0.125),   # Silence\\n  (56, 0.5),  # G#3 half note\\n  (57, 0.5),   # A3 half note\\n  (0, 0.125),  # Silence \\n  (55, 0.5),  # G3 half note\\n  (57, 0.5),   # A3 half note\\n  (0, 0.125),  # Silence \\n  (54, 0.75),  # F#3 dotted half note\\n  (0, 0.125),  # Silence\\n  (52, 0.5),   # E3 half note\\n  (0, 0.125),  # Silence\\n  (50, 0.5),  # D3 half note\\n  (52, 0.5),   # E3 half note\\n  (0, 0.125),  # Silence\\n  (54, 0.5),  # F#3 half note\\n  (55, 0.5),   # G3 half note\\n  (0, 0.125),  # Silence\\n  (57, 0.5),  # A3 half note\\n  (55, 0.5),   # G3 half note\\n  (0, 0.125),  # Silence\\n  (54, 0.5),  # F#3 half note\\n  (52, 0.75),  # E3 dotted half note\\n  (0, 0.125),  # Silence\\n  (50, 0.5),  # D3 half note\\n  (0, 0.125),  # Silence\\n  (48, 0.5),  # C3 half note\\n  (50, 0.5),   # D3 half note\\n  (48, 0.75),  # C3 dotted half note\\n]\\n```\\n\\nThis melody starts on A3 (57) and ends on C3 (48), using multiple pitches, some in large intervals and others in small steps. The melody employs a minor scale with semitone shifts for added dissonance, which contributes to the sad and dramatic mood. The rhythm consists of half notes and dotted half notes interspersed with silences. This should give a sad, dramatic and complex sound.'"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composition = conversation.predict(input=\"\"\"\n",
    "    Yes, generate a longer melody very sad and dramatic.\n",
    "    \"\"\")\n",
    "composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the LLM output string into a Python dictionary\n",
    "\n",
    "Let's create an LLM output JSON and use LangChain to parse that output.\n",
    "Let's extract the melody data and format that output into a JSON format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_schema = ResponseSchema(name=\"description\",\n",
    "                             description=\"Extract any sentences describing the melody \\\n",
    "                            an output them as a text.\")\n",
    "melody_pitch_duration_data_schema = ResponseSchema(name=\"melody_pitch_duration_data\",\n",
    "                                    description=\"Extract the composed melody, \\\n",
    "                                    and output them as a comma separated Python list like \\\n",
    "                                    [[60, 0.125], [62, 0.25], ...]\")\n",
    "\n",
    "response_schemas = [description_schema, \n",
    "                    melody_pitch_duration_data_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "description: Extract any sentences describing the melody \\\n",
    "an output them as a text.\n",
    "\n",
    "melody_pitch_duration_data: Extract the composed melody, \\\n",
    "and output them as a comma separated Python list. like \\\n",
    "[[60, 0.125], [62, 0.25], ...]\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "description\n",
    "melody_pitch_duration_data\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template=review_template)\n",
    "\n",
    "messages = prompt.format_messages(text=composition, \n",
    "                                format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"description\": \"Sad and dramatic melodies often involve minor keys, slower rhythms, larger leaps in intervals, and varied dynamics. This melody starts on A3 (57) and ends on C3 (48), using multiple pitches, some in large intervals and others in small steps. The melody employs a minor scale with semitone shifts for added dissonance, which contributes to the sad and dramatic mood. The rhythm consists of half notes and dotted half notes interspersed with silences. This should give a sad, dramatic and complex sound.\",\n",
      "\t\"melody_pitch_duration_data\": [[57, 0.5], [0, 0.125], [56, 0.5], [57, 0.5], [0, 0.125], [55, 0.5], [57, 0.5], [0, 0.125], [54, 0.75], [0, 0.125], [52, 0.5], [0, 0.125], [50, 0.5], [52, 0.5], [0, 0.125], [54, 0.5], [55, 0.5], [0, 0.125], [57, 0.5], [55, 0.5], [0, 0.125], [54, 0.5], [52, 0.75], [0, 0.125], [50, 0.5], [0, 0.125], [48, 0.5], [50, 0.5], [48, 0.75]]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Sad and dramatic melodies often involve minor keys, slower rhythms, larger leaps in intervals, and varied dynamics. This melody starts on A3 (57) and ends on C3 (48), using multiple pitches, some in large intervals and others in small steps. The melody employs a minor scale with semitone shifts for added dissonance, which contributes to the sad and dramatic mood. The rhythm consists of half notes and dotted half notes interspersed with silences. This should give a sad, dramatic and complex sound.',\n",
       " 'melody_pitch_duration_data': [[57, 0.5],\n",
       "  [0, 0.125],\n",
       "  [56, 0.5],\n",
       "  [57, 0.5],\n",
       "  [0, 0.125],\n",
       "  [55, 0.5],\n",
       "  [57, 0.5],\n",
       "  [0, 0.125],\n",
       "  [54, 0.75],\n",
       "  [0, 0.125],\n",
       "  [52, 0.5],\n",
       "  [0, 0.125],\n",
       "  [50, 0.5],\n",
       "  [52, 0.5],\n",
       "  [0, 0.125],\n",
       "  [54, 0.5],\n",
       "  [55, 0.5],\n",
       "  [0, 0.125],\n",
       "  [57, 0.5],\n",
       "  [55, 0.5],\n",
       "  [0, 0.125],\n",
       "  [54, 0.5],\n",
       "  [52, 0.75],\n",
       "  [0, 0.125],\n",
       "  [50, 0.5],\n",
       "  [0, 0.125],\n",
       "  [48, 0.5],\n",
       "  [50, 0.5],\n",
       "  [48, 0.75]]}"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[57, 0.5],\n",
       " [0, 0.125],\n",
       " [56, 0.5],\n",
       " [57, 0.5],\n",
       " [0, 0.125],\n",
       " [55, 0.5],\n",
       " [57, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.75],\n",
       " [0, 0.125],\n",
       " [52, 0.5],\n",
       " [0, 0.125],\n",
       " [50, 0.5],\n",
       " [52, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.5],\n",
       " [55, 0.5],\n",
       " [0, 0.125],\n",
       " [57, 0.5],\n",
       " [55, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.5],\n",
       " [52, 0.75],\n",
       " [0, 0.125],\n",
       " [50, 0.5],\n",
       " [0, 0.125],\n",
       " [48, 0.5],\n",
       " [50, 0.5],\n",
       " [48, 0.75]]"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melody_data = output_dict.get('melody_pitch_duration_data')\n",
    "melody_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_to_midi = config['note_to_midi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A#0': 22, 'A#1': 34, 'A#2': 46, 'A#3': 58, 'A#4': 70, 'A#5': 82, 'A#6': 94, 'A#7': 106, 'A#8': 118, 'A0': 21, 'A1': 33, 'A2': 45, 'A3': 57, 'A4': 69, 'A5': 81, 'A6': 93, 'A7': 105, 'A8': 117, 'Ab0': 20, 'Ab1': 32, 'Ab2': 44, 'Ab3': 56, 'Ab4': 68, 'Ab5': 80, 'Ab6': 92, 'Ab7': 104, 'Ab8': 116, 'B0': 23, 'B1': 35, 'B2': 47, 'B3': 59, 'B4': 71, 'B5': 83, 'B6': 95, 'B7': 107, 'B8': 119, 'Bb0': 22, 'Bb1': 34, 'Bb2': 46, 'Bb3': 58, 'Bb4': 70, 'Bb5': 82, 'Bb6': 94, 'Bb7': 106, 'Bb8': 118, 'C#0': 13, 'C#1': 25, 'C#2': 37, 'C#3': 49, 'C#4': 61, 'C#5': 73, 'C#6': 85, 'C#7': 97, 'C#8': 109, 'C#9': 121, 'C0': 12, 'C1': 24, 'C2': 36, 'C3': 48, 'C4': 60, 'C5': 72, 'C6': 84, 'C7': 96, 'C8': 108, 'C9': 120, 'D#0': 15, 'D#1': 27, 'D#2': 39, 'D#3': 51, 'D#4': 63, 'D#5': 75, 'D#6': 87, 'D#7': 99, 'D#8': 111, 'D#9': 123, 'D0': 14, 'D1': 26, 'D2': 38, 'D3': 50, 'D4': 62, 'D5': 74, 'D6': 86, 'D7': 98, 'D8': 110, 'D9': 122, 'Db0': 13, 'Db1': 25, 'Db2': 37, 'Db3': 49, 'Db4': 61, 'Db5': 73, 'Db6': 85, 'Db7': 97, 'Db8': 109, 'Db9': 121, 'E0': 16, 'E1': 28, 'E2': 40, 'E3': 52, 'E4': 64, 'E5': 76, 'E6': 88, 'E7': 100, 'E8': 112, 'E9': 124, 'Eb0': 15, 'Eb1': 27, 'Eb2': 39, 'Eb3': 51, 'Eb4': 63, 'Eb5': 75, 'Eb6': 87, 'Eb7': 99, 'Eb8': 111, 'Eb9': 123, 'F#0': 18, 'F#1': 30, 'F#2': 42, 'F#3': 54, 'F#4': 66, 'F#5': 78, 'F#6': 90, 'F#7': 102, 'F#8': 114, 'F#9': 126, 'F0': 17, 'F1': 29, 'F2': 41, 'F3': 53, 'F4': 65, 'F5': 77, 'F6': 89, 'F7': 101, 'F8': 113, 'F9': 125, 'G#0': 20, 'G#1': 32, 'G#2': 44, 'G#3': 56, 'G#4': 68, 'G#5': 80, 'G#6': 92, 'G#7': 104, 'G#8': 116, 'G0': 19, 'G1': 31, 'G2': 43, 'G3': 55, 'G4': 67, 'G5': 79, 'G6': 91, 'G7': 103, 'G8': 115, 'G9': 127, 'Gb0': 18, 'Gb1': 30, 'Gb2': 42, 'Gb3': 54, 'Gb4': 66, 'Gb5': 78, 'Gb6': 90, 'Gb7': 102, 'Gb8': 114, 'Gb9': 126}"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_to_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(melody_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "from midiutil import MIDIFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_to_midi_mapping():\n",
    "    \"\"\"\n",
    "    Create a dictionary to map note names to MIDI note numbers.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary mapping note names to MIDI note numbers.\n",
    "    \"\"\"\n",
    "    # Define the mapping from note names to MIDI note numbers\n",
    "    note_to_midi = config['note_to_midi']\n",
    "    return note_to_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi_file(notes, filename=\"melody.mid\"):\n",
    "    \"\"\"\n",
    "    Create a MIDI file from a list of notes.\n",
    "    \n",
    "    Parameters:\n",
    "        notes (list): List of notes to include in the MIDI file.\n",
    "        filename (str): Name of the output MIDI file.\n",
    "    \"\"\"\n",
    "    # Initialize a MIDI file with one track\n",
    "    midi = MIDIFile(1)\n",
    "    \n",
    "    # Set the instrument to Acoustic Grand Piano (program number 0)\n",
    "    # The order is track, time, channel, program\n",
    "    midi.addProgramChange(0, 0, 0, 0)\n",
    "    \n",
    "    # Add notes to the MIDI file\n",
    "    for start_time, (pitch, duration) in enumerate(notes):\n",
    "        midi.addNote(0, 0, pitch, start_time, duration, 100)\n",
    "        \n",
    "    # Save the MIDI file\n",
    "    with open(filename, \"wb\") as output_file:\n",
    "        midi.writeFile(output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[57, 0.5],\n",
       " [0, 0.125],\n",
       " [56, 0.5],\n",
       " [57, 0.5],\n",
       " [0, 0.125],\n",
       " [55, 0.5],\n",
       " [57, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.75],\n",
       " [0, 0.125],\n",
       " [52, 0.5],\n",
       " [0, 0.125],\n",
       " [50, 0.5],\n",
       " [52, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.5],\n",
       " [55, 0.5],\n",
       " [0, 0.125],\n",
       " [57, 0.5],\n",
       " [55, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.5],\n",
       " [52, 0.75],\n",
       " [0, 0.125],\n",
       " [50, 0.5],\n",
       " [0, 0.125],\n",
       " [48, 0.5],\n",
       " [50, 0.5],\n",
       " [48, 0.75]]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melody_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: [[57, 0.5], [0, 0.125], [56, 0.5], [57, 0.5], [0, 0.125], [55, 0.5], [57, 0.5], [0, 0.125], [54, 0.75], [0, 0.125], [52, 0.5], [0, 0.125], [50, 0.5], [52, 0.5], [0, 0.125], [54, 0.5], [55, 0.5], [0, 0.125], [57, 0.5], [55, 0.5], [0, 0.125], [54, 0.5], [52, 0.75], [0, 0.125], [50, 0.5], [0, 0.125], [48, 0.5], [50, 0.5], [48, 0.75]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/markeyser/Projects/genai-music-lab/notebooks/music_v02.ipynb Cell 32\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markeyser/Projects/genai-music-lab/notebooks/music_v02.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mast\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markeyser/Projects/genai-music-lab/notebooks/music_v02.ipynb#Y116sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Assuming melody_data is a string like '[[76, 0.125], [72, 0.125], ...]'\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/markeyser/Projects/genai-music-lab/notebooks/music_v02.ipynb#Y116sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m melody_data_list \u001b[39m=\u001b[39m ast\u001b[39m.\u001b[39;49mliteral_eval(melody_data)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markeyser/Projects/genai-music-lab/notebooks/music_v02.ipynb#Y116sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Now melody_data_list should be a list of lists\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markeyser/Projects/genai-music-lab/notebooks/music_v02.ipynb#Y116sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(melody_data_list)\n",
      "File \u001b[0;32m~/miniforge3/envs/genai-music-lab-env/lib/python3.10/ast.py:110\u001b[0m, in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[39mreturn\u001b[39;00m left \u001b[39m-\u001b[39m right\n\u001b[1;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[0;32m--> 110\u001b[0m \u001b[39mreturn\u001b[39;00m _convert(node_or_string)\n",
      "File \u001b[0;32m~/miniforge3/envs/genai-music-lab-env/lib/python3.10/ast.py:109\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m             \u001b[39mreturn\u001b[39;00m left \u001b[39m-\u001b[39m right\n\u001b[0;32m--> 109\u001b[0m \u001b[39mreturn\u001b[39;00m _convert_signed_num(node)\n",
      "File \u001b[0;32m~/miniforge3/envs/genai-music-lab-env/lib/python3.10/ast.py:83\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m operand\n\u001b[0;32m---> 83\u001b[0m \u001b[39mreturn\u001b[39;00m _convert_num(node)\n",
      "File \u001b[0;32m~/miniforge3/envs/genai-music-lab-env/lib/python3.10/ast.py:74\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_convert_num\u001b[39m(node):\n\u001b[1;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(node, Constant) \u001b[39mor\u001b[39;00m \u001b[39mtype\u001b[39m(node\u001b[39m.\u001b[39mvalue) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m, \u001b[39mcomplex\u001b[39m):\n\u001b[0;32m---> 74\u001b[0m         _raise_malformed_node(node)\n\u001b[1;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m node\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/miniforge3/envs/genai-music-lab-env/lib/python3.10/ast.py:71\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m lno \u001b[39m:=\u001b[39m \u001b[39mgetattr\u001b[39m(node, \u001b[39m'\u001b[39m\u001b[39mlineno\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     70\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m on line \u001b[39m\u001b[39m{\u001b[39;00mlno\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 71\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mnode\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: malformed node or string: [[57, 0.5], [0, 0.125], [56, 0.5], [57, 0.5], [0, 0.125], [55, 0.5], [57, 0.5], [0, 0.125], [54, 0.75], [0, 0.125], [52, 0.5], [0, 0.125], [50, 0.5], [52, 0.5], [0, 0.125], [54, 0.5], [55, 0.5], [0, 0.125], [57, 0.5], [55, 0.5], [0, 0.125], [54, 0.5], [52, 0.75], [0, 0.125], [50, 0.5], [0, 0.125], [48, 0.5], [50, 0.5], [48, 0.75]]"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Assuming melody_data is a string like '[[76, 0.125], [72, 0.125], ...]'\n",
    "melody_data_list = ast.literal_eval(melody_data)\n",
    "\n",
    "# Now melody_data_list should be a list of lists\n",
    "print(melody_data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[57, 0.5],\n",
       " [0, 0.125],\n",
       " [56, 0.5],\n",
       " [57, 0.5],\n",
       " [0, 0.125],\n",
       " [55, 0.5],\n",
       " [57, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.75],\n",
       " [0, 0.125],\n",
       " [52, 0.5],\n",
       " [0, 0.125],\n",
       " [50, 0.5],\n",
       " [52, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.5],\n",
       " [55, 0.5],\n",
       " [0, 0.125],\n",
       " [57, 0.5],\n",
       " [55, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.5],\n",
       " [52, 0.75],\n",
       " [0, 0.125],\n",
       " [50, 0.5],\n",
       " [0, 0.125],\n",
       " [48, 0.5],\n",
       " [50, 0.5],\n",
       " [48, 0.75],\n",
       " [57, 0.5],\n",
       " [0, 0.125],\n",
       " [56, 0.5],\n",
       " [57, 0.5],\n",
       " [0, 0.125],\n",
       " [55, 0.5],\n",
       " [57, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.75],\n",
       " [0, 0.125],\n",
       " [52, 0.5],\n",
       " [0, 0.125],\n",
       " [50, 0.5],\n",
       " [52, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.5],\n",
       " [55, 0.5],\n",
       " [0, 0.125],\n",
       " [57, 0.5],\n",
       " [55, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.5],\n",
       " [52, 0.75],\n",
       " [0, 0.125],\n",
       " [50, 0.5],\n",
       " [0, 0.125],\n",
       " [48, 0.5],\n",
       " [50, 0.5],\n",
       " [48, 0.75],\n",
       " [57, 0.5],\n",
       " [0, 0.125],\n",
       " [56, 0.5],\n",
       " [57, 0.5],\n",
       " [0, 0.125],\n",
       " [55, 0.5],\n",
       " [57, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.75],\n",
       " [0, 0.125],\n",
       " [52, 0.5],\n",
       " [0, 0.125],\n",
       " [50, 0.5],\n",
       " [52, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.5],\n",
       " [55, 0.5],\n",
       " [0, 0.125],\n",
       " [57, 0.5],\n",
       " [55, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.5],\n",
       " [52, 0.75],\n",
       " [0, 0.125],\n",
       " [50, 0.5],\n",
       " [0, 0.125],\n",
       " [48, 0.5],\n",
       " [50, 0.5],\n",
       " [48, 0.75],\n",
       " [57, 0.5],\n",
       " [0, 0.125],\n",
       " [56, 0.5],\n",
       " [57, 0.5],\n",
       " [0, 0.125],\n",
       " [55, 0.5],\n",
       " [57, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.75],\n",
       " [0, 0.125],\n",
       " [52, 0.5],\n",
       " [0, 0.125],\n",
       " [50, 0.5],\n",
       " [52, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.5],\n",
       " [55, 0.5],\n",
       " [0, 0.125],\n",
       " [57, 0.5],\n",
       " [55, 0.5],\n",
       " [0, 0.125],\n",
       " [54, 0.5],\n",
       " [52, 0.75],\n",
       " [0, 0.125],\n",
       " [50, 0.5],\n",
       " [0, 0.125],\n",
       " [48, 0.5],\n",
       " [50, 0.5],\n",
       " [48, 0.75]]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melody_data_double = melody_data + melody_data +  melody_data + melody_data\n",
    "melody_data_double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save the MIDI file\n",
    "create_midi_file(melody_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduce a MIDI file in GarageBand on macOS using Python\n",
    "\n",
    "Here is a complete guide for sending MIDI to GarageBand from Python using mido:\n",
    "\n",
    "#### Send MIDI to GarageBand from Python\n",
    "\n",
    "This guide covers how to reproduce a MIDI file in GarageBand on macOS using Python and the mido module.\n",
    "\n",
    "##### Steps\n",
    "\n",
    "1. Set up MIDI in Audio MIDI Setup\n",
    "\n",
    "- Open Applications\n",
    "- Open Audio MIDI Setup\n",
    "- Enable the IAC Driver\n",
    "- Connect a MIDI keyboard and test  \n",
    "\n",
    "2. Create a Software Instrument track in GarageBand\n",
    "\n",
    "- Launch GarageBand\n",
    "- Create a new Software Instrument track \n",
    "- Select a sound like piano or synth \n",
    "\n",
    "3. Install mido\n",
    "\n",
    "```bash\n",
    "pip install mido\n",
    "```\n",
    "\n",
    "4. Import mido and get GarageBand port name\n",
    "\n",
    "```python\n",
    "import mido\n",
    "\n",
    "ports = mido.get_output_names()\n",
    "# Look for the GarageBand port, e.g. 'IAC Driver Bus 1'\n",
    "gb_port = ports[0] \n",
    "```\n",
    "\n",
    "5. Open MIDI file and GarageBand port\n",
    "\n",
    "```python\n",
    "mid = mido.MidiFile('melody.mid')\n",
    "\n",
    "port = mido.open_output(gb_port)\n",
    "```\n",
    "\n",
    "6. Send MIDI messages to GarageBand\n",
    "\n",
    "```python \n",
    "for message in mid.play():\n",
    "    port.send(message)\n",
    "```\n",
    "\n",
    "7. Listen to the MIDI file reproduced in GarageBand!\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "- Audio MIDI Setup enables virtual MIDI ports like the IAC Driver\n",
    "- GarageBand needs an instrument track to receive the MIDI notes\n",
    "- mido parses the MIDI file and sends messages to the port  \n",
    "- The port name must match GarageBand's exactly\n",
    "\n",
    "And that's it! The MIDI file will be played in GarageBand using the sounds from the instrument track. Let me know if you have any other questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mido and get GarageBand port name\n",
    "ports = mido.get_output_names()\n",
    "# Look for the GarageBand port, e.g. 'IAC Driver Bus 1'\n",
    "gb_port = ports[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'melody.mid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/markeyser/Projects/genai-music-lab/notebooks/music_v02.ipynb Cell 37\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markeyser/Projects/genai-music-lab/notebooks/music_v02.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Open MIDI file and GarageBand port\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/markeyser/Projects/genai-music-lab/notebooks/music_v02.ipynb#X51sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mid \u001b[39m=\u001b[39m mido\u001b[39m.\u001b[39;49mMidiFile(\u001b[39m'\u001b[39;49m\u001b[39mmelody.mid\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markeyser/Projects/genai-music-lab/notebooks/music_v02.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m port \u001b[39m=\u001b[39m mido\u001b[39m.\u001b[39mopen_output(gb_port)\n",
      "File \u001b[0;32m~/miniforge3/envs/genai-music-lab-env/lib/python3.10/site-packages/mido/midifiles/midifiles.py:320\u001b[0m, in \u001b[0;36mMidiFile.__init__\u001b[0;34m(self, filename, file, type, ticks_per_beat, charset, debug, clip, tracks)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load(file)\n\u001b[1;32m    319\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m    321\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load(file)\n\u001b[1;32m    322\u001b[0m \u001b[39m# merge tracks at load time to prevent timing error on\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[39m# first call to __iter__()\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'melody.mid'"
     ]
    }
   ],
   "source": [
    "# Open MIDI file and GarageBand port\n",
    "mid = mido.MidiFile('melody.mid')\n",
    "port = mido.open_output(gb_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/markeyser/Projects/genai-music-lab/notebooks/music_v02.ipynb Cell 38\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markeyser/Projects/genai-music-lab/notebooks/music_v02.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Send MIDI messages to GarageBand\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/markeyser/Projects/genai-music-lab/notebooks/music_v02.ipynb#X52sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m message \u001b[39min\u001b[39;00m mid\u001b[39m.\u001b[39mplay():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markeyser/Projects/genai-music-lab/notebooks/music_v02.ipynb#X52sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     port\u001b[39m.\u001b[39msend(message)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mid' is not defined"
     ]
    }
   ],
   "source": [
    "# Send MIDI messages to GarageBand\n",
    "for message in mid.play():\n",
    "    port.send(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-music-lab-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
